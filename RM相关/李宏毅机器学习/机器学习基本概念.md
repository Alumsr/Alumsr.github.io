---
link: https://www.youtube.com/watch?v=Ye018rCVvOo
dg-publish: true
---
1. 机器学习
	- 任务
		- regression:回归,输出预测的标量
		- classification:分类,输出给定选项中的正确项
		- structured learning:创造有结构的事物(docs,images)
	- 模型:一个函数,有以下要素
		- 输入x
		- 输出y
		- 参数bias(偏置),weight(权重)
	- label:数据对应的正确返回值
3. loss损失
	- 是什么:关于b,w的函数$L(b,w)$
	- 作用:根据一组data和label计算给定b,w参数的模型的损失值
	- 例子
		- MAE绝对值误差$e=|y-\hat y|$
		- MSE均方误差$e=(y-\hat{y})$
		- 交叉熵误差
	- loss函数可对b,w作出**error surface**图
		- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介 [Ye018rCVvOo - 640x480 - 24m33s].png]]
		- 图中形成等高线
		- 高度:损失函数的值
4. optimization
	- 是什么:优化模型的参数
	- 简单方法:gradient descent梯度下降(微分)
	- 方法:[link](https://www.youtube.com/watch?v=Ye018rCVvOo&t=1533.1422288359788)
	- global minima & local minima
		- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介 [Ye018rCVvOo - 640x480 - 35m31s].png]]
- Training
	- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介 [Ye018rCVvOo - 640x480 - 41m36s].png]]

- Step 1:线性模型以外--以sigmoid/ReLU为例
	- ![[Pasted image 20231029144402.png]]
	- model bias:模型过于简单导致无法描述特征
	- continuous function<--piecewise functions<--sigmoid functions
	- sigmoid
		- ![[Pasted image 20231029144930.png]]
		- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介 [bHcJCp2Fyxs - 925x694 - 17m12s].png]][sigmoid](https://www.youtube.com/watch?v=bHcJCp2Fyxs)
	- hard sigmoid![[Pasted image 20231029145337.png]]
	- [总结](https://www.youtube.com/watch?v=bHcJCp2Fyxs&t=739.089255):参数w,b到sigmoid到所求函数
		- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介 [bHcJCp2Fyxs - 925x694 - 14m06s].png]]
	- [函数模型解释](https://www.youtube.com/watch?v=bHcJCp2Fyxs&t=1028.848404)
		- [矩阵运算](https://www.youtube.com/watch?v=bHcJCp2Fyxs&t=1266.2262741652023)
			- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介 [bHcJCp2Fyxs - 925x694 - 21m52s].png]]
		- 符号表示 & 线性代数表示
			- ![[Hung-yi Lee - 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介 [bHcJCp2Fyxs - 925x694 - 25m28s].png]]
		- [参数更新(微分)](https://www.youtube.com/watch?v=bHcJCp2Fyxs&t=2108.420983)
			- update:一次参数更新
			- epoch:数据分为多个batch,所有batch轮流用来更新一遍参数
		- [ReLU\*2->hard sigmoid](https://www.youtube.com/watch?v=bHcJCp2Fyxs&t=2601.595041)
		- activate functions
		- 重复:网络加深
	- Hyper parameters
	- 起名:神经元&神经网络&神经层&深度学习
		- ![[Pasted image 20231029160507.png]]
	- overfitting过拟合